# THD-PLV2 - Turtlebot3 maze challenges (Thomas Bergwinkl)

The challenges 0 to 3 focus more on the usage of the API.
This document is about approaches for autonomous robots, and that's why the first four challenges are not covered.

## Challenge 4 - First approach

The maze of challenge 4 is U-shaped and would require two 90 degree turns in the most basic version to get from the starting point to the red wall.

We started with a technical description of the goal and a programmatic way to check if the goal was reached.
That allows us to break down all other steps in between.

### Detect the center of the red wall

The goal is to drive the robot in front of the red wall and stop there.
More precisely, we want to reach the point 90 degrees in front of the center of the red wall with a predefined safe distance.  
After some debugging, we knew that the LIDAR sensor could provide us all the required information.
The `intensity` value is `2.0` if the laser hits a red wall.
Since there could be some noise in the signal, a range between `1.5` and `2.5` is used for the detection. 
The `ranges` values can be used to measure the distance.
This information is available for full 360 degrees in 1 degree steps.
If there is a hit to a red wall, the start and end can be found by searching for all consecutive values in both directions.
Some additional logic is required to jump from 360 to 0 degrees if the line crosses 0 degrees.
The center of the line is the center of the red wall.

### Approaching the red wall

Once the red wall is found, the robot can turn towards the center of the red wall and move forward until the `ranges` value for 0 degrees is equal to or smaller than the safe distance.
Until the robot stops, the center of the red wall is continuously recalculated, and the direction is corrected for better results.  

### Find the red wall

Until a red wall is found, the following steps were processed:

1) detect red wall
2) turn 90 degree
3) move forward until the distance to the wall is equals to or smaller than the safe distance
4) goto 1)

Because of the safety gaps we had to add, the robot was lost in an endless loop or lost in a corner.
Some simple recovery strategies were tested with mixed results.
After we had a look at the maze of challenge 5, we decided to switch to a different approach.

## Challenges 4 & 5

The maze of challenge 5 has more turns than in challenge 4.
Simple 90 degree turns would almost all the time end up in endless loops.
Driving along the wall could solve this problem.
No matter how many turns there are, the walls are always connected, and at some point, the red wall will show up.
Before the robot can drive along the wall, it needs to reach the wall.
A state machine is used to handle these steps.

### State machine 

![state diagram](_static/state_diagram.svg)

The `STATE_SEARCH` is the initial state when it's unknown whether the robot is already next to a wall or if it needs to drive towards one first.
If the robot is not next to a wall, the state is changed to `STATE_TO_WALL`.
In this state, the robot will drive forward until the LIDAR measures a distance smaller than a configured safe distance.
The distance is measured 360 degrees in case the next wall shows up left or right and not in the front.
Once a wall is found, it switches to state `STATE_ALONG_WALL`.
If that state is reached, no further state changes will happen.
A control loop ensures that the robot stays next to the wall until the red wall is reached.

### Implementation Details

#### Event Handling

All state changes of the state machine are triggered by messages from the LIDAR sensor.
Only the orientation from the odometry is used as an additional parameter.
The orientation is assigned to a member variable to make it accessible in the LIDAR callback.
The state machine handler and the control loop is implemented inside the LIDAR callback.

#### Control Loop

The control loop measures the average distance in a 10 degree window from 270 degrees to the front.
Based on the difference to the target distance, the angular speed is linear adapted to correct the distance.
A 50 degree window to the front is used to detect walls or obstacles.
The linear speed is adapted minimal distance to the front to be able to make more precise movements along corners.
If the distance is below a certain threshold, the linear speed is set to 0.
This logic worked pretty well along straight walls but sometimes led to 360 degree turns in corners.
The robot turned too early, which caused increasing distance measures to the wall.
A second correction factor was added that contains the ratio of the forward distance (260-270 degrees) and the backward distance (270-280).
This factor alone could be used to drive parallel to the wall.
Equally weighted, the combined factor allows the robot to make more stable turns at corners.
For more stability, the angular speed and the linear speed are clamped in a predefined range.

#### Detect being next to the red wall

The same logic that was described earlier to find the center of the red wall is also used for this approach.
As the robot no longer heads directly towards the red wall, the center must be at 270 degrees.
The robot stops if the center is at 270 degrees with a tolerance of +-10 degrees. 

### Problems and possible future improvements

The constants used in the code were chosen by trial and error.
As they affect each other, tweaking them was sometimes complicated and even led to breaking a previously working solution.
A full PID controller may have caused less chaotic behavior on changes to the constants. 

The current implementation of the control loop causes some oscillation.
A PID controller should solve that problem.
